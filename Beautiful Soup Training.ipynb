{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Turtle Shellter\n",
      "  </title>\n",
      "  <link href=\"https://fonts.googleapis.com/css?family=Poppins\" rel=\"stylesheet\"/>\n",
      "  <link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"banner\">\n",
      "   <h1>\n",
      "    The Shellter\n",
      "   </h1>\n",
      "   <span class=\"brag\">\n",
      "    The #1 Turtle Adoption website!\n",
      "   </span>\n",
      "  </div>\n",
      "  <div class=\"about\">\n",
      "   <p class=\"text\">\n",
      "    Click to learn more about each turtle\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"grid\">\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"aesop.html\">\n",
      "     <img class=\"headshot\" src=\"aesop.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Aesop\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"caesar.html\">\n",
      "     <img class=\"headshot\" src=\"caesar.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Caesar\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"sulla.html\">\n",
      "     <img class=\"headshot\" src=\"sulla.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Sulla\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"spyro.html\">\n",
      "     <img class=\"headshot\" src=\"spyro.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Spyro\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"zelda.html\">\n",
      "     <img class=\"headshot\" src=\"zelda.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Zelda\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"bandicoot.html\">\n",
      "     <img class=\"headshot\" src=\"bandicoot.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Bandicoot\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"hal.html\">\n",
      "     <img class=\"headshot\" src=\"hal.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Hal\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"mock.html\">\n",
      "     <img class=\"headshot\" src=\"mock.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Mock\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"box adopt\">\n",
      "    <a class=\"more-info\" href=\"sparrow.html\">\n",
      "     <img class=\"headshot\" src=\"sparrow.png\"/>\n",
      "    </a>\n",
      "    <p>\n",
      "     Captain Sparrow\n",
      "    </p>\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "\n",
      "\n",
      "<h1>The Shellter</h1>\n",
      "\n",
      "\n",
      "<span class=\"brag\">The #1 Turtle Adoption website!</span>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests # Library that has the information for HTML communication (Think mailman on railroad track from your house to business)\n",
    "from bs4 import BeautifulSoup as bs # BeautifulSoup goes over HTML information to find relevent info.\n",
    "\n",
    "webpage_response = requests.get('https://s3.amazonaws.com/codecademy-content/courses/beautifulsoup/shellter.html') # Gets the response from the mailman (TCP)\n",
    "\n",
    "webpage = webpage_response.content # Stores the content from the requested connection to the variable\n",
    "\n",
    "#print (webpage) # Prints the \n",
    "\n",
    "soup = bs(webpage) # soup now has the readable html code. \"html.parser\" is the standard parser used\n",
    "\n",
    "print(soup.prettify()) #Prints out the code and makes it look nice. String format\n",
    "#print(soup.p.string) # Attributes find the first 'p' tag, and print the string contents within. \n",
    "\n",
    "for child in soup.div.children: # Prints the children of the first div bracket\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def has_banner_class_and_hello_world(tag):\n",
    "    return tag.attr('class') == \"banner\" and tag.string == \"Hello world\"\n",
    "\n",
    "soup.find_all(has_banner_class_and_hello_world)\n",
    "\n",
    "The above code would look for the following element: `<div class=\"banner\">Hello world</div>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find all - For HTML\n",
    "turtle_links = soup.find_all(['a']) # Finds all of the hyperlinks within the website and prints them\n",
    "\n",
    "#print(turtle_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSS Selector\n",
    "links = []\n",
    "#go through all of the a tags and get the links associated with them\"\n",
    "for a in turtle_links:\n",
    "    links.append(prefix+a[\"href\"])\n",
    "    \n",
    "#Define turtle_data:\n",
    "turtle_data = {}\n",
    "\n",
    "\n",
    "for link in links: # Iterates through each link in the links dictionary\n",
    "  webpage = requests.get(link) # Gets the data for each link in links\n",
    "  turtle = bs(webpage.content, \"html.parser\") # Makes the data easier to read\n",
    "  turtle_name = turtle.select(\".name\")[0] # Stores the first entry of class 'name' to turtle_name\n",
    "  turtle_data[turtle_name] = [] # sets the name as the first key in the dictionary with an empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aesop\n",
      "0\n",
      "Caesar\n",
      "1\n",
      "Sulla\n",
      "2\n",
      "Spyro\n",
      "3\n",
      "Zelda\n",
      "4\n",
      "Bandicoot\n",
      "5\n",
      "Hal\n",
      "6\n",
      "Mock\n",
      "7\n",
      "Sparrow\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "## Reading Texts\n",
    "\n",
    "\n",
    "prefix = \"https://s3.amazonaws.com/codecademy-content/courses/beautifulsoup/\"\n",
    "webpage_response = requests.get('https://s3.amazonaws.com/codecademy-content/courses/beautifulsoup/shellter.html')\n",
    "\n",
    "webpage = webpage_response.content\n",
    "soup = bs(webpage, \"html.parser\")\n",
    "\n",
    "turtle_links = soup.find_all(\"a\")\n",
    "links = []\n",
    "#go through all of the a tags and get the links associated with them\"\n",
    "for a in turtle_links:\n",
    "    links.append(prefix+a[\"href\"]) # Adds the individual turtle name to each of the remaining links\n",
    "\n",
    "#Define turtle_data:\n",
    "turtle_data = {}\n",
    "x = 0\n",
    "\n",
    "#follow each link:\n",
    "for link in links:\n",
    "  webpage = requests.get(link)\n",
    "  turtle = bs(webpage.content, \"html.parser\")\n",
    "  turtle_name = turtle.select(\".name\")[0].get_text()\n",
    "  print(turtle_name)\n",
    "    \n",
    "  print(x)\n",
    "  x += 1\n",
    "  #stats = turtle.find(\"ul\") # Finds all HTML elements that are ul\n",
    "  #stats_text = stats.get_text(\"|\") # Puts the barrier \"|\" on all of the entries specified above\n",
    "  #turtle_data[turtle_name] = stats_text.split(\"|\") # Splits each of the \"|\" with a new line entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of understanding BeautifulSoup\n",
    "\n",
    "#### 1. Get the url of the site\n",
    "\n",
    "#### 2. get the content of the website with .get('url').content\n",
    "\n",
    "#### 3. convert to BeautifulSoup using the website content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
